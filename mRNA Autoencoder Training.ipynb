{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8807adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Detected?: True\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import gzip\n",
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "import errno\n",
    "from Bio import SeqIO\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "GPU_PRESENT = [torch.cuda.device (i) for i in range (torch.cuda.device_count ())]!=[]\n",
    "print(\"GPU Detected?: \"+str(GPU_PRESENT))\n",
    "if GPU_PRESENT:\n",
    "    torch.set_default_device('cuda')\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "    #import cupy as cp\n",
    "\n",
    "\n",
    "fastqs = glob.glob(\"http:\\\\/home/grant/NNRNA/fastqs/*/*.fastq.gz\")\n",
    "\n",
    "PAD_SIZE=1000\n",
    "BATCH_SIZE=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1a7ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqs = glob.glob(\"\\\\\\\\wsl.localhost\\\\Debian\\\\home\\\\grant\\\\NNRNA\\\\fastqs\\\\*\\\\*.fastq.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25b7dca1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "flatten() received an invalid combination of arguments - got (), but expected one of:\n * (Tensor input, int start_dim, int end_dim, name out_dim)\n * (Tensor input, int start_dim, int end_dim)\n * (Tensor input, name start_dim, name end_dim, name out_dim)\n * (Tensor input, tuple of names dims, name out_dim)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4568\\3384032678.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfastqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4568\\3384032678.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: flatten() received an invalid combination of arguments - got (), but expected one of:\n * (Tensor input, int start_dim, int end_dim, name out_dim)\n * (Tensor input, int start_dim, int end_dim)\n * (Tensor input, name start_dim, name end_dim, name out_dim)\n * (Tensor input, tuple of names dims, name out_dim)\n"
     ]
    }
   ],
   "source": [
    "enc.fit_transform(np.array([\"A\",\"T\", \"C\", \"G\", \"N\"]).reshape(-1,1))\n",
    "\n",
    "def get_seqios(file):\n",
    "    seqs = []\n",
    "    with gzip.open(file, 'rt') as fastq:\n",
    "        for index, record in enumerate(SeqIO.parse(fastq, 'fastq')):\n",
    "            seqs.append(str(record.seq))\n",
    "\n",
    "    return seqs\n",
    "\n",
    "def parse_reads(record, pad_size=PAD_SIZE):\n",
    "    x_in = np.array(list(record))\n",
    "    arr = enc.fit_transform(x_in.reshape(-1,1)).toarray()\n",
    "    delta = len(arr)-pad_size\n",
    "\n",
    "    if delta>0:\n",
    "        #random crop\n",
    "        shift=np.random.randint(0,delta)\n",
    "        x_out = arr[shift:shift+pad_size]\n",
    "\n",
    "    else:\n",
    "        arr.resize((pad_size, 4), refcheck=False)\n",
    "        x_out=arr\n",
    "\n",
    "    return x_out\n",
    "\n",
    "                  \n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths):\n",
    "        self.data = paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        path = self.data[idx]\n",
    "        out = parse_reads(path)\n",
    "        out = out.reshape(PAD_SIZE, 4)\n",
    "        out = torch.tensor(out).to(torch.float)\n",
    "        return out\n",
    "                  \n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            #torch.nn.Linear(PAD_SIZE, 400, 1),\n",
    "            #torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.Conv1d(PAD_SIZE, 800, 4),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv1d(800, 400, 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.flatten(),\n",
    "            torch.nn.Linear(400, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 16)\n",
    "        )\n",
    "         \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 400),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(400, 800),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(800, (4*PAD_SIZE)),\n",
    "            torch.nn.Sigmoid()\n",
    "            \n",
    "            #torch.nn.Linear(400, PAD_SIZE, 1, 1),\n",
    "            #torch.nn.Sigmoid()\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "                  \n",
    "def train_encoder(model, dataset, epochs, steps, batch_size, lr=0.1, decay=1e-9):\n",
    "    num_epochs = epochs\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr = lr ,weight_decay = decay)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=0,\n",
    "                                             generator=torch.Generator(device='cuda'))\n",
    "\n",
    "    losses=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"epoch\"+str(epoch))\n",
    "        data = next(iter(dataloader))\n",
    "        for batch_index, doc in enumerate(data):\n",
    "            recon = model(doc)\n",
    "            #Loss function\n",
    "            loss = loss_function(recon, doc)\n",
    "            if batch_index%10==0:\n",
    "                print(\"Batch: \"+str(batch_index))\n",
    "                print(\"loss\"+str(loss))\n",
    "\n",
    "            # Gradients are set to zero,\n",
    "            # Gradient is computed and stored.\n",
    "            # .step() performs parameter update.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Storing the losses\n",
    "            losses.append(loss)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "dataset = Dataset(fastqs)\n",
    "model = AE()\n",
    "epochs = 10\n",
    "steps = 10\n",
    "batch_size=100\n",
    "lr = 0.1\n",
    "decay = 1e-7\n",
    "\n",
    "train_encoder(model,\n",
    "             dataset,\n",
    "             epochs,\n",
    "             steps,\n",
    "             batch_size,\n",
    "              lr,\n",
    "              decay\n",
    "             )\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26d496bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./RNA_Autoencoder.state_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d626e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.linear.Linear"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74537c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._VariableFunctionsClass.flatten>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bce329c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
